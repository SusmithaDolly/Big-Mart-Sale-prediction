{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n",
    "os.chdir('C:/Users/puran/Desktop/DS material/EDA')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "train = pd.read_csv(\"Train.csv\")\n",
    "test = pd.read_csv(\"Test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Variable Identification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.Uni-Variate Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dependent Variable (Continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Item_Outlet_Sales.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(train.Item_Outlet_Sales,bins=100,rwidth=1)\n",
    "plt.xlabel(\"Item_Outlet_Sales\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it is a right skewd variable and would need some data transformation to treat its skewness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Independent Variables (numeric variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[[\"Item_Weight\",\"Item_Visibility\",\"Item_MRP\"]].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above that Item_Weight has a lot of missing values. While visualizing this variable we need to take note of this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(221)\n",
    "plt.hist(train.Item_Weight.dropna(),rwidth=1,bins=150) #rwidth sets width of bars.If it's 1 then the bars will touch each other\n",
    "plt.xlabel(\"Item_Weight\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.subplot(222)\n",
    "plt.hist(train.Item_Visibility,bins=50) #rwidth sets width of bars.If it's 1 then the bars will touch each other\n",
    "plt.xlabel(\"Item_Visibility\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.subplot(223)\n",
    "plt.hist(train.Item_MRP,bins=100)\n",
    "plt.xlabel(\"Item_MRP\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.tight_layout()          # this function makes sure the plots dont overlap.Comment this and execute to observe the difference\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__\n",
    "\n",
    "- There seems to be no clear-cut pattern in Item_Weight.<br/>\n",
    "- Item_Visibility is right-skewed and should be transformed to curb its skewness.<br/>\n",
    "- We can clearly see 4 different distributions for Item_MRP. It is an interesting insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Independent Variables (categorical variables)__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Item_Fat_Content\"].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the figure above, ‘LF’, ‘low fat’, and ‘Low Fat’ are the same category and can be combined into one.<br/> Similarly we can be done for ‘reg’ and ‘Regular’ into one. After making these corrections we’ll plot the same figure again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.loc[train.Item_Fat_Content==\"LF\",\"Item_Fat_Content\"]      = \"Low Fat\"\n",
    "train.loc[train.Item_Fat_Content==\"low fat\",\"Item_Fat_Content\"] = \"Low Fat\"\n",
    "train.loc[train.Item_Fat_Content==\"reg\",\"Item_Fat_Content\"]     = \"Regular\"\n",
    "train[\"Item_Fat_Content\"].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Item_Type\n",
    "train[\"Item_Type\"].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Outlet Identifier\n",
    "train[\"Outlet_Identifier\"].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Outlet_Size\"].value_counts(dropna=False).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Outlet_Establishment_Year\"].value_counts().plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Outlet_Type\"].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=train.Item_Weight,y=train.Item_Outlet_Sales)\n",
    "plt.xlabel(\"Item_Weight\")\n",
    "plt.ylabel(\"Item_Outlet_Sales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=train.Item_Visibility,y=train.Item_Outlet_Sales)\n",
    "plt.xlabel(\"Item_Visibility\")\n",
    "plt.ylabel(\"Item_Outlet_Sales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=train.Item_MRP,y=train.Item_Outlet_Sales)\n",
    "plt.xlabel(\"Item_MRP\")\n",
    "plt.ylabel(\"Item_Outlet_Sales\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__\n",
    "\n",
    "- Item_Outlet_Sales is spread well across the entire range of the Item_Weight without any obvious pattern.\n",
    "- In Item_Visibility vs Item_Outlet_Sales, there is a string of points at Item_Visibility = 0.0 which seems strange as item visibility cannot be completely zero. We will take note of this issue and deal with it in the later stages.\n",
    "- In the third plot of Item_MRP vs Item_Outlet_Sales, we can clearly see 4 segments of prices that can be used in feature engineering to create a new variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Target Variable vs Independent Categorical Variables ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=train.Item_Outlet_Sales,y=train.Item_Type)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=train.Item_Fat_Content,y=train.Item_Outlet_Sales)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=train.Outlet_Identifier,x=train.Item_Outlet_Sales)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Observations__\n",
    "\n",
    "- Distribution of Item_Outlet_Sales across the categories of Item_Type is not very distinct and same is the case with Item_Fat_Content.\n",
    "- The distribution for OUT010 and OUT019 categories of Outlet_Identifier are quite similar and very much different from the rest of the categories of Outlet_Identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=train.Outlet_Size,y=train.Item_Outlet_Sales)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=train.Outlet_Location_Type,y=train.Item_Outlet_Sales)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=train.Outlet_Type,x=train.Item_Outlet_Sales)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__Observations__\n",
    "\n",
    "- Tier 1 and Tier 3 locations of Outlet_Location_Type look similar.\n",
    "- In the Outlet_Type plot, Grocery Store has most of its data points around the lower sales values as compared to the other categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Missing Value Treatment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you can get the # missing values in two ways\n",
    "print(sum(np.isnan(train.Item_Weight)))\n",
    "print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We’ll now impute Item_Weight with mean weight based on the Item_Identifier variable.\n",
    "ind = np.isnan(train.Item_Weight)\n",
    "for index,row in train.iterrows():\n",
    "    if ind[index]==True:\n",
    "        item = row[\"Item_Identifier\"]\n",
    "        train.loc[index,\"Item_Weight\"]=(np.mean(train.loc[train.Item_Identifier==item,\"Item_Weight\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Item_Identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sum(np.isnan(train.Item_Weight)))\n",
    "#print(train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"Outlet_Size\"].value_counts(dropna=False).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the distribution we conclude that the missing value's distribution is same as the small's distribution.Therefore we impute the missing values with \"Small\".Here we will use pandas fillna method to impute the value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.Outlet_Size=train.Outlet_Size.fillna(\"Small\")\n",
    "train[\"Outlet_Size\"].value_counts(dropna=False).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is another way of writing the code to impute.The end output is same as what we did for Item_Weight\n",
    "ind = train.Item_Visibility==0\n",
    "avg_Item_Visibility = train.groupby('Item_Identifier').Item_Visibility.mean()\n",
    "#print(avg_Item_Visibility)\n",
    "print(\"Number of zero records: \"+str(sum(ind)))\n",
    "for index, row in train.iterrows():\n",
    "    if ind[index]==True:\n",
    "        train.loc[index, 'Item_Visibility'] = avg_Item_Visibility[row.Item_Identifier]\n",
    "ind = train.Item_Visibility==0\n",
    "print(\"Number of zero records after imputing: \"+str(sum(ind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(avg_Item_Visibility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6&7.Variable Transformation/Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perishable = [\"Breads\", \"Breakfast\", \"Dairy\", \"Fruits and Vegetables\", \"Meat\", \"Seafood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_perishable = [\"Baking Goods\", \"Canned\", \"Frozen Foods\", \"Hard Drinks\", \"Health and Hygiene\", \"Household\", \"Soft Drinks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Item_Type_New']=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new feature 'Item_Type_new'\n",
    "for index, row in train.iterrows():\n",
    "    if (row[\"Item_Type\"] in perishable):\n",
    "        train.loc[index,'Item_Type_New']=\"perishable\"\n",
    "        #print(train.loc[index,\"Item_Type_New\"])\n",
    "    elif(row[\"Item_Type\"] in non_perishable):\n",
    "        train.loc[index,'Item_Type_New']=\"non_perishable\"\n",
    "    else:\n",
    "        train.loc[index,'Item_Type_New']=\"not_sure\"\n",
    "#print(train['Item_Type_New'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# importing linear regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lreg = LinearRegression()\n",
    "\n",
    "# for cross validation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "X = train.drop('Item_Outlet_Sales',1)\n",
    "\n",
    "\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X,train.Item_Outlet_Sales, test_size =0.3)\n",
    "\n",
    "# training a linear regression model on train\n",
    "\n",
    "lreg.fit(x_train,y_train)\n",
    "\n",
    "# predicting on cv\n",
    "\n",
    "pred_cv = lreg.predict(x_cv)\n",
    "\n",
    "# calculating mse\n",
    "\n",
    "mse = np.mean((pred_cv - y_cv)**2)\n",
    "\n",
    "# evaluation using r-square\n",
    "\n",
    "print(lreg.score(x_cv,y_cv))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_t = lreg.predict(x_train)\n",
    "mse = np.mean((pred_t - y_train)**2)\n",
    "print(lreg.score(x_train,y_train))\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()\n",
    "predictors = x_train.columns\n",
    "coef = Series(lreg.coef_,predictors).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='Modal Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lassoReg = Lasso(alpha=0.05, normalize=True)\n",
    "\n",
    "lassoReg.fit(x_train,y_train)\n",
    "\n",
    "pred = lassoReg.predict(x_cv)\n",
    "\n",
    "# calculating mse\n",
    "\n",
    "mse = np.mean((pred_cv - y_cv)**2)\n",
    "print(mse)\n",
    "print(lassoReg.score(x_cv,y_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()\n",
    "predictors = x_train.columns\n",
    "\n",
    "coef = Series(lassoReg.coef_,predictors).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='Modal Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######Dummy Variable Creation######\n",
    "ind= np.isnan(train[\"Item_Weight\"])\n",
    "train=train[-ind]\n",
    "mylist = list(train.select_dtypes(include=['object']).columns)\n",
    "\n",
    "dummies = pd.get_dummies(train[mylist], prefix= mylist)\n",
    "\n",
    "train.drop(mylist, axis=1, inplace = True)\n",
    "\n",
    "X = pd.concat([train,dummies], axis =1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# importing linear regression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lreg = LinearRegression()\n",
    "\n",
    "# for cross validation\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = X.drop('Item_Outlet_Sales',1)\n",
    "\n",
    "\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X,train.Item_Outlet_Sales, test_size =0.3)\n",
    "\n",
    "# training a linear regression model on train\n",
    "\n",
    "lreg.fit(x_train,y_train)\n",
    "\n",
    "# predicting on cv\n",
    "\n",
    "pred_cv = lreg.predict(x_cv)\n",
    "\n",
    "# calculating mse\n",
    "\n",
    "mse = np.mean((pred_cv - y_cv)**2)\n",
    "\n",
    "# evaluation using r-square\n",
    "\n",
    "print(lreg.score(x_cv,y_cv))\n",
    "print(mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()\n",
    "predictors = x_train.columns\n",
    "\n",
    "coef = Series(lreg.coef_,predictors).sort_values()\n",
    "\n",
    "coef.plot(kind='bar', title='Modal Coefficients')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing the best features\n",
    "import statsmodels.api as sm\n",
    "X2 = sm.add_constant(x_train)\n",
    "est = sm.OLS(y_train, X2)\n",
    "est2 = est.fit()\n",
    "print(est2.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
